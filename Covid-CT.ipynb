{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path1 = r'C:\\Users\\Arundhathi A\\Desktop\\TRAIN1\\COVID_19/2020.02.10.20021584-p6-52%12.png'\n",
    "path2 = r'C:\\Users\\Arundhathi A\\Desktop\\TRAIN1\\NON_COVID\\23.png'\n",
    "path3 = r'C:\\Users\\Arundhathi A\\Desktop\\TRAIN1'\n",
    "path4 = r'C:\\Users\\Arundhathi A\\Desktop\\TEST'\n",
    "\n",
    "img=cv2.imread(path1)\n",
    "img1=cv2.imread(path2)\n",
    "cv2.imshow('COVID19 Positive Sample case', img)\n",
    "cv2.imshow('COVID 19 Negative Sample Case',img1)\n",
    "\n",
    "# Building the CNN\n",
    "import tensorflow as tf\n",
    "# Importing the Keras libraries and packages\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "classifier = models.Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(layers.Conv2D(32, (3, 3), input_shape = (256, 256, 1), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "## Adding a third convolutional layer\n",
    "classifier.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(layers.Conv2D(16, (3, 3), activation = 'relu'))\n",
    "classifier.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "# Flattening\n",
    "classifier.add(layers.Flatten())\n",
    "\n",
    "# Full connection\n",
    "classifier.add(layers.Dense(units = 1024, activation = 'relu'))\n",
    "classifier.add(layers.Dense(units = 512, activation = 'relu'))\n",
    "\n",
    "classifier.add(layers.Dense(units = 2, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy','AUC'])\n",
    "\n",
    "# Fitting the CNN to the images\n",
    "\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(path3,\n",
    "                                                 target_size = (256, 256),\n",
    "                                                 batch_size = 8,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(path4,\n",
    "                                            target_size = (256, 256),\n",
    "                                            batch_size = 8,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            color_mode='grayscale',\n",
    "                                            shuffle=False)\n",
    "\n",
    "nb_train_samples=539\n",
    "nb_validation_samples=207\n",
    "batch_size=8\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history=classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = nb_train_samples//batch_size,\n",
    "                         epochs = 30,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = nb_validation_samples//batch_size,callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'],label='Train Loss')\n",
    "plt.plot(history.history['val_loss'],label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'],label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['AUC'],label='Train AUC')\n",
    "plt.plot(history.history['val_AUC'],label='Validation AUC')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
